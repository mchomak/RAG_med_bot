"""
Конфигурация RAG-системы для работы с медицинской документацией
"""

import os
from pathlib import Path

# ==================== ПУТИ ====================
# Базовая директория проекта
BASE_DIR = Path(__file__).parent
STORAGE_DIR = BASE_DIR / "storage"

# ==================== МОДЕЛИ ====================
# Ollama LLM настройки
OLLAMA_MODEL = "llama3.1:8b"  # Llama 3.1 8B через Ollama
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_REQUEST_TIMEOUT = 120.0  # Таймаут запроса в секундах

# Эмбеддинг модель (русскоязычная)
EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-large"
EMBEDDING_DIMENSION = 1024  # Размерность векторов для multilingual-e5-large

# ==================== ПАРАМЕТРЫ ИНДЕКСАЦИИ ====================
# Размер чанков (chunks) при разбиении документов
CHUNK_SIZE = 512  # Оптимальный размер для медицинских текстов
CHUNK_OVERLAP = 50  # Перекрытие между чанками для сохранения контекста

# Параметры парсинга документов
ENCODING = "utf-8"  # Кодировка для чтения txt файлов

# ==================== ПАРАМЕТРЫ ПОИСКА ====================
# Количество наиболее релевантных чанков для генерации ответа
SIMILARITY_TOP_K = 3

# Порог схожести (similarity threshold) для фильтрации результатов
SIMILARITY_CUTOFF = 0.5  # Минимальная схожесть для включения в контекст

# ==================== CHROMADB НАСТРОЙКИ ====================
# Имя коллекции в ChromaDB
CHROMA_COLLECTION_NAME = "medical_documents"

# Путь для персистентного хранения ChromaDB
CHROMA_PERSIST_DIR = str(STORAGE_DIR / "chroma_db")

# ==================== ПРОМПТЫ ====================
# Системный промпт для LLM (на русском языке)
SYSTEM_PROMPT = """Ты - полезный AI-ассистент, специализирующийся на медицинской информации.

Твоя задача - отвечать на вопросы пользователя, используя ТОЛЬКО информацию из предоставленных документов.

ВАЖНЫЕ ПРАВИЛА:
1. Отвечай ТОЛЬКО на основе предоставленного контекста из документов
2. Если информации нет в документах - честно скажи об этом
3. Не придумывай и не домысливай информацию
4. Отвечай на русском языке четко и структурированно
5. Если уместно, используй списки и пункты для лучшей читаемости
6. Ссылайся на источники, когда это возможно

Формат ответа:
- Сначала дай прямой ответ на вопрос
- Затем, если нужно, добавь дополнительные детали
- Если информации недостаточно, явно укажи это
"""

# Промпт для форматирования контекста
CONTEXT_PROMPT_TEMPLATE = """
Контекст из документов:
{context_str}

Вопрос пользователя: {query_str}

Ответ:
"""

# Промпт для случая, когда информация не найдена
NO_CONTEXT_RESPONSE = """
К сожалению, я не нашел релевантной информации в предоставленных документах для ответа на ваш вопрос.

Возможные причины:
- Информация отсутствует в загруженных документах
- Вопрос сформулирован слишком специфично
- Попробуйте переформулировать вопрос

Попробуйте задать вопрос по-другому или убедитесь, что нужные документы загружены.
"""

# ==================== ПАРАМЕТРЫ ГЕНЕРАЦИИ ====================
# Параметры генерации ответов LLM
TEMPERATURE = 0.1  # Низкая температура для более точных и предсказуемых ответов
MAX_TOKENS = 1024  # Максимальная длина ответа

# ==================== ИНТЕРФЕЙС ====================
# Параметры отображения
SHOW_PROGRESS_BAR = True  # Показывать прогресс-бар при индексации
SHOW_SOURCES = True  # Показывать источники в ответах
MAX_SOURCE_PREVIEW_LENGTH = 200  # Максимальная длина превью источника

# Цвета для вывода (используются в rich/colorama)
COLOR_SCHEME = {
    "user": "cyan",
    "assistant": "green",
    "system": "yellow",
    "error": "red",
    "info": "blue",
    "source": "magenta"
}

# ==================== ВАЛИДАЦИЯ ====================
# Поддерживаемые форматы файлов
SUPPORTED_FILE_EXTENSIONS = [".txt", ".pdf", ".docx"]

# Минимальное количество документов для индексации
MIN_DOCUMENTS = 1

# Максимальный размер файла (в байтах) - 10 MB
MAX_FILE_SIZE = 10 * 1024 * 1024

# ==================== КОМАНДЫ ====================
# Команды интерактивного режима
COMMANDS = {
    "exit": "Выход из программы",
    "reload": "Переиндексация документов",
    "help": "Показать справку по командам",
    "sources": "Показать источники последнего ответа",
    "clear": "Очистить экран"
}